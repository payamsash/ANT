{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Simulating EEG and running a Neurofeedback session\n\nThis example demonstrates how to simulate EEG data with sinusoidal sources \nin a specific brain region and use it for a neurofeedback session using the\nANT package.\n\nWe cover the following steps:\n\n1. Simulate raw EEG data with sinusoidal activity in a cortical label.\n2. Record a baseline session to extract blink templates and the inverse operator.\n3. Run a main neurofeedback session using multiple modalities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Simulate EEG recording\nFirst, we simulate EEG data by adding sinusoidal activity in the\npericalcarine region of the left hemisphere. This will generate a raw \nMNE-Python object that can be used in our neurofeedback session.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom pathlib import Path\nimport numpy as np\nfrom mne.io import read_raw_brainvision\nfrom mne.label import select_sources\nfrom mne.datasets import fetch_fsaverage\nfrom mne import (\n    set_log_level,\n    rename_channels,\n    make_forward_solution,\n    read_labels_from_annot,\n    make_ad_hoc_cov\n)\nfrom mne.simulation import (\n    SourceSimulator,\n    simulate_raw,\n    add_noise,\n    add_eog\n)\n\ndef simulate_eeg_raw(\n    brain_label,\n    frequency,\n    amplitude,\n    duration,\n    gap_duration,\n    n_repetition,\n    start,\n    iir_filter=[0.2, -0.2, 0.04],\n    fname_save=None,\n    verbose=None\n):\n    \"\"\"Simulate EEG data with a sinusoidal source in a given brain label.\n\n    Parameters\n    ----------\n    brain_label : str\n        Name (regexp) of the cortical label in which to simulate the source.\n    frequency : float\n        Frequency of the simulated sine wave (Hz).\n    amplitude : float\n        Amplitude scaling factor of the simulated signal.\n    duration : float\n        Duration of each simulated signal epoch in seconds.\n    gap_duration : float\n        Interval (in seconds) between consecutive signal epochs.\n    n_repetition : int\n        Number of signal epochs to simulate.\n    start : float\n        Start time of the first simulated signal, in seconds.\n    iir_filter : array_like\n        IIR filter coefficients (denominator) used when adding noise.\n    verbose : bool | str | int | None\n        Control verbosity of the logging output.\n\n    Returns\n    -------\n    raw : instance of mne.io.Raw\n        The simulated raw EEG object.\n    \"\"\"\n\n    set_log_level(verbose=verbose)\n\n    # Load example data\n    data_dir = Path.cwd().parent / \"data\" \n    fname_vhdr = data_dir / \"sample\" / \"sample_data.vhdr\" \n    raw = read_raw_brainvision(fname_vhdr, preload=True)\n\n    # Montage and drop ECG channels\n    new_ch_names = raw.info['ch_names'].copy()\n    new_ch_names[58] = 'Fpz'  # rename FPz\n    mapping = dict(zip(raw.info['ch_names'], new_ch_names))\n    rename_channels(raw.info, mapping)\n    raw.drop_channels(ch_names=[\"HRli\", \"HRre\"], on_missing='raise')\n    raw.set_montage(\"easycap-M1\", on_missing='warn')\n\n    # FSaverage files\n    fs_dir = fetch_fsaverage()\n    subjects_dir = os.path.dirname(fs_dir)\n    subject = \"fsaverage\"\n    trans = \"fsaverage\"\n    src = os.path.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n    bem = os.path.join(fs_dir, \"bem\", \"fsaverage-5120-5120-5120-bem-sol.fif\")\n\n    # Forward solution\n    fwd = make_forward_solution(raw.info, trans=trans, src=src, bem=bem)\n    src = fwd[\"src\"]\n\n    # Source activation\n    tstep = 1.0 / raw.info[\"sfreq\"]\n    selected_label = read_labels_from_annot(\n        subject, regexp=brain_label, subjects_dir=subjects_dir\n    )[0]\n\n    label = select_sources(\n        subject,\n        selected_label,\n        location=\"center\",\n        extent=1,\n        grow_outside=True,\n        subjects_dir=subjects_dir\n    )\n\n    source_time_series = np.sin(\n        2.0 * np.pi * frequency * np.arange(int(duration * raw.info[\"sfreq\"])) * tstep\n    ) * 10e-9 * amplitude\n\n    gap_duration_s = gap_duration * raw.info[\"sfreq\"]\n    start_s = start * raw.info[\"sfreq\"]\n    events = np.zeros((n_repetition, 3), int)\n    events[:, 0] = start_s + gap_duration_s * np.arange(n_repetition)\n    events[:, 2] = 1  \n\n    source_simulator = SourceSimulator(fwd[\"src\"], tstep=tstep)\n    source_simulator.add_data(label, source_time_series, events)\n    raw = simulate_raw(raw.info, source_simulator, forward=fwd)\n    cov = make_ad_hoc_cov(raw.info)\n    add_noise(raw, cov, iir_filter=iir_filter)\n    add_eog(raw)\n\n    # Save simulated raw\n    sim_dir = data_dir / \"simulated\"\n    os.makedirs(sim_dir, exist_ok=True)\n    if fname_save is None:\n        raw.save(fname=sim_dir / f\"{brain_label}_{frequency}Hz_{amplitude}-raw.fif\", overwrite=True)\n    else:\n        raw.save(fname=fname_save)\n\n    return raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Record baseline session\nWe create a `NFRealtime` object to record a baseline session. This step is\nrequired to extract the blink template and the inverse operator for the \nsubject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ant import NFRealtime\nimport time\n\nkwargs_sim = {\n    \"brain_label\": \"pericalcarine-lh\",\n    \"frequency\": 10,\n    \"amplitude\": 1,\n    \"duration\": 1,\n    \"gap_duration\": 6,\n    \"n_repetition\": 8,\n    \"start\": 5,\n    \"fname_save\": None\n}\nraw = simulate_eeg_raw(**kwargs_sim)\n\nbrain_label = \"pericalcarine-lh\"\nfrequency = 10\namplitude = 2\nfname = Path.cwd().parent / \"data\" / \"simulated\" / f\"{brain_label}_{frequency}Hz_{amplitude}-raw.fif\"\nkwargs = {\n    \"subject_id\": \"bert\",\n    \"visit\": 6,\n    \"subjects_dir\": Path.cwd().parent / \"data\" / \"subjects\",\n    \"montage\": \"easycap-M1\",\n    \"mri\": False,\n    \"artifact_correction\": False,\n    \"verbose\": False\n}\n\nnf = NFRealtime(session=\"baseline\", **kwargs)\n# Connect to a mock LSL stream (we are using our simulated data)\n\nnf.connect_to_lsl(mock_lsl=True, fname=fname)\ntime.sleep(4)\n\n# Record baseline for 6 seconds\nnf.record_baseline(baseline_duration=6)\n\n# Extract blink template for artifact correction\nnf.get_blink_template()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run the main neurofeedback session\nNow we run the main neurofeedback session using multiple modalities.\nThe results will be saved in the subject's directory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mods = [\n    \"sensor_power\",\n    \"band_ratio\",\n    \"entropy\",\n    \"sensor_connectivity\",\n    \"sensor_graph\",\n    \"individual_peak_power\"\n]\n\nnf.record_main(\n    duration=60, \n    modality=mods,\n    picks=None,\n    winsize=1,\n    estimate_delays=True,\n    modality_params=None,\n    show_raw_signal=False,\n    show_nf_signal=True,\n    time_window=20,\n    show_design_viz=False,\n    design_viz=\"VisualRorschach\",\n    show_brain_activation=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Results\nThe neurofeedback session is complete. Results are automatically saved \nin the subject directory specified during the creation of the NFRealtime\nobject. You can now visualize or analyze the feedback signals as needed.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}